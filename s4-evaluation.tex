\section{Evaluation}

\subsection{Evaluation Procedure}

\subsection{Java}

To evaluate the performance of RefDiff in Java we initially use an oracle proposed by Tsantalis et al.~\cite{xx}. This oracle includes 3,188 manually-validated refactoring instances, detected in 185 open source projects, and covering 15 refactoring operations. \todo{discutir quais sao cobertos ou nao por RefDiff 2.0}. We also use this oracle to compare RefDiff's precision and recall against RefactoringMiner, a state-of-the-art tool for detecting refactorings in Java.

First, we run RefDiff on the oracle commits. For each commit with a detected refactoring $r$ we checked whether $r$ is in the oracle. If yes, $r$ is a true positive; otherwise, $r$ was evaluated by two authors of this paper, to check whether it is a true positive or not. This extra manual validation is needed because the initial oracle must not be granted as complete, i.e., including all refactorings performed in the set of analysed commits. In reality, this oracle was constructed based on an initial list of refactorings produced by RefactoringMiner and RefDiff 1.0. For this reason, it might miss true refactorings only detected by the improved implementation of RefDiff, described in this paper.

After following this procedure, RefDiff 2.0 detected 406 new refactoring instances (i.e., not listed in the initial oracle), which were  validated by two paper's authors, called here validators.  In the case of 269 refactorings (66\%), the validators agreed on their classification, including 184 refactorings labelled as true positives by both validators and 85 labelled as false positives. After this initial and independent validation, the validators discussed together the remaining 137 cases (34\%), to reach an agreement. As a result, xx refactorings were considered true positives and xx refactorings were classified as false positives. Figure xx shows an example of true positive. \todo{ilustrar um caso bem obvio de TP}. Figure xx shows an example of false positive \todo{ilustrar com um caso bem dificil e confuso, de FP}.

In summary, after these two steps (indenpendent validation and consensuous meeting), xx refactorings instances were  classified as true positives and therefore included in the oracle. The expanded oracle includes xx refactoring instances (xx\% more than the initial one) and it is publicly available at: xx)

\subsubsection{Precision}
\label{SecPrecisionProcedure}

The procedure to compute the precision of our approach consists of the following steps:

\begin{enumerate}  
\item We selected the 20 most popular repositories of a target programming language. For this, we queried the GitHub API for repositories, sorting by stars count---which is an indicator of popularity~\cite{icsme2016,jss-2018-github-stars} ---and filtering by the programming language.
The resulting list of repositories was manually inspected to discard the ones that were not actual software projects, e.g., tutorials or code samples.
For each selected repository, we created a fork of it to preserve its version history from future changes pushed to the original project.

\item We ran RefDiff in the version history of each repository and recorded the refactorings found.
The version history was inspected by navigating the commit graph backwards, starting from the most recent commit in the master branch.
For each commit, we compared its source code with its predecessor using RefDiff.
It is worth noting that merge commits, which have two predecessors, were ignored.
The rationale for such decision is that comparing a merge commit with their predecessors would result in duplicated reports of refactorings applied in the commits prior to the merge operation.
Moreover, to avoid over-representing projects with longer histories, we established a limit of 500 commits per repository.

\item Given the list of refactorings instances found by RefDiff, we randomly selected 10 instances of each refactoring type to assess whether they correspond to actual refactorings (true positives), or incorrect reports (false positives).
When applying the random selection, we enforced the constraint that we should not select two refactoring instances performed in the same commit.
This way, we avoided selecting very similar refactoring instances which were performed in batch, e.g., multiple classes or functions moved together.
To confirm each refactoring instance, one of the authors inspected the diff of the code changes in the corresponding commit.
\end{enumerate}

After performing the three steps described above, we were able to compute the precision as $P = \mathit{TP} / (\mathit{TP} + \mathit{FP})$, where $\mathit{TP}$ is the number of true positives and $\mathit{FP}$ is the number of false positives.



\subsubsection{Recall}

The procedure to compute the recall of our approach consists of the following steps:

\begin{enumerate}  
\item We queried the GitHub API to find refactorings documented in commits from the 20 repositories selected in the first step of the precision evaluation procedure (Section~\ref{SecPrecisionProcedure}). Such queries consist in searching for keywords denoting a particular type of refactoring in the commit message. For example, when looking for \emph{Rename Function} refactoring instances, we built a query that looks for commits which contain the keywords \texttt{rename} and \texttt{function} in their commit messages.

\item Given the results of a query, we manually inspected the commit message and the diff of the source code to confirm the applied refactoring. We repeated this procedure until we found 10 instances of each refactoring type or there were no more results to inspect. Each confirmed refactoring was recorded in a normalized textual format compatible with the output of RefDiff.
%It is worth noting that, during this procedure, most of the results were discarded because the commit message did not actually documented a refactoring. Besides, the diff of some of the commits were so large that could not be displayed in the user interface. In summary, we only registered the refactoring instances that we could confirm both in the commit message and in the code diff.

\item We ran RefDiff in the commits that contained refactorings found in the previous step to assess whether they are reported (true positives) or missed (false negatives). 

\end{enumerate}

After performing the three steps described above, we were able to compute the recall as $R = \mathit{TP} / (\mathit{TP} + \mathit{FN})$, where $\mathit{TP}$ is the number of true positives and $\mathit{FN}$ is the number of false negatives.


\subsection{JavaScript evaluation results}

The following GitHub repositories were selected to run evaluation procedure:
\textsc{facebook/\-react}, 
\textsc{vuejs/\-vue}, 
\textsc{d3/\-d3}, 
\textsc{face\-book/\-react-native}, 
\textsc{angular/\-angular.js}, 
\textsc{face\-book/\-create-react-app}, 
\textsc{jquery/\-jquery}, 
\textsc{atom/\-atom}, 
\textsc{axios/\-axios}, 
\textsc{mrdoob/\-three.js}, 
\textsc{socketio/\-socket.io}, 
\textsc{reduxjs/\-redux}, 
\textsc{webpack/\-webpack}, 
\textsc{Semantic-Org/\-Semantic-UI}, 
\textsc{hakimel/\-reveal.js}, 
\textsc{meteor/\-meteor}, 
\textsc{expressjs/\-express}, 
\textsc{mui-org/\-material-ui}, 
\textsc{chartjs/\-Chart.js}


\begin{table}[htbp]
\renewcommand{\arraystretch}{1.2}
\caption{JavaScript precision results}
\label{TabResultJsPrecison}
\centering
\begin{tabular}{@{}lrrrll@{}}
\toprule
Refactoring Type & TP & FP & Precision\\
\midrule
Move File & 10 & 0 & \xbar{1.00} \\
Move Class & 2 & 0 & \xbar{1.00} \\
Move Function & 9 & 1 & \xbar{0.90} \\
Rename File & 10 & 0 & \xbar{1.00} \\
Rename Class & 5 & 0 & \xbar{1.00} \\
Rename Function & 8 & 2 & \xbar{0.80} \\
Move and Rename File & 10 & 0 & \xbar{1.00} \\
Move and Rename Function & 8 & 2 & \xbar{0.80} \\
Extract Function & 9 & 1 & \xbar{0.90} \\
Inline Function & 8 & 2 & \xbar{0.80} \\
\addlinespace
Total & 79 & 8 & \xbar{0.91} \\
\bottomrule
\end{tabular}
\end{table}

\begin{table}[htbp]
\renewcommand{\arraystretch}{1.2}
\caption{JavaScript recall results}
\label{TabResultJsRecall}
\centering
\begin{tabular}{@{}lrrrll@{}}
\toprule
Refactoring Type & TP & FN & Recall\\
\midrule
Move File & 10 & 0 & \xbar{1.00} \\
Move Function & 10 & 0 & \xbar{1.00} \\
Rename File & 8 & 2 & \xbar{0.80} \\
Rename Function & 9 & 1 & \xbar{0.90} \\
Move and Rename File & 3 & 0 & \xbar{1.00} \\
Move and Rename Function & 6 & 1 & \xbar{0.86} \\
Extract Function & 9 & 1 & \xbar{0.90} \\
Inline Function & 2 & 3 & \xbar{0.40} \\
\addlinespace
Total & 57 & 8 & \xbar{0.88} \\
\bottomrule
\end{tabular}
\end{table}


\subsection{C evaluation results}

The following GitHub repositories were selected to run evaluation procedure:
\textsc{torvalds/\-linux}, 
\textsc{firehol/\-netdata}, 
\textsc{antirez/\-redis}, 
\textsc{git/\-git}, 
\textsc{Bilibili/\-ijkplayer}, 
\textsc{php/\-php-src}, 
\textsc{wg/\-wrk}, 
\textsc{ggreer/\-the\_silver\_searcher}, 
\textsc{kripken/\-emscripten}, 
\textsc{vim/\-vim}, 
\textsc{stedolan/\-jq}, 
\textsc{FFmpeg/\-FFmpeg}, 
\textsc{tmux/\-tmux}, 
\textsc{vurtun/\-nuklear}, 
\textsc{obsproject/\-obs-studio}, 
\textsc{libuv/\-libuv}, 
\textsc{swoole/\-swoole-src}, 
\textsc{curl/\-curl}, 
\textsc{irungentoo/\-toxcore}, 
\textsc{pjreddie/\-darknet} 


\begin{table}[htbp]
\renewcommand{\arraystretch}{1.2}
\caption{C precision results}
\label{TabResultCPrecison}
\centering
\begin{tabular}{@{}lrrrll@{}}
\toprule
Refactoring Type & TP & FP & Precision\\
\midrule
Move File & 10 & 0 & \xbar{1.00} \\
Move Function & 8 & 2 & \xbar{0.80} \\
Rename File & 10 & 0 & \xbar{1.00} \\
Rename Function & 9 & 1 & \xbar{0.90} \\
Move and Rename Function & 8 & 2 & \xbar{0.80} \\
Change Signature & 10 & 0 & \xbar{1.00} \\
Extract Function & 10 & 0 & \xbar{1.00} \\
Inline Function & 5 & 5 & \xbar{0.50} \\
\addlinespace
Total & 70 & 10 & \xbar{0.88} \\
\bottomrule
\end{tabular}
\end{table}


\begin{table}[htbp]
\renewcommand{\arraystretch}{1.2}
\caption{C recall results}
\label{TabResultCRecall}
\centering
\begin{tabular}{@{}lrrrll@{}}
\toprule
Refactoring Type & TP & FN & Recall\\
\midrule
Change Signature & 9 & 1 & \xbar{0.90} \\
Extract Function & 7 & 3 & \xbar{0.70} \\
Inline Function & 9 & 1 & \xbar{0.90} \\
Move File & 10 & 0 & \xbar{1.00} \\
Move Function & 8 & 2 & \xbar{0.80} \\
Move and Rename File & 10 & 0 & \xbar{1.00} \\
Move and Rename Function & 9 & 1 & \xbar{0.90} \\
Rename File & 10 & 0 & \xbar{1.00} \\
Rename Function & 10 & 0 & \xbar{1.00} \\
\addlinespace
Total & 82 & 8 & \xbar{0.91} \\
\bottomrule
\end{tabular}
\end{table}


